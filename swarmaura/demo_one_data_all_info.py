#!/usr/bin/env python3
"""
DEMO: One Dataset, All Information
Shows how a single unified dataset powers all routing intelligence
"""

import os
import sys
import time
from pathlib import Path

# Add backend to path
sys.path.append("/Users/krishnabhatnagar/hackharvard/swarmaura/backend")

def demo_unified_data_power():
    """Demonstrate how one dataset provides all information"""
    print("üéØ DEMO: ONE DATASET, ALL INFORMATION")
    print("=" * 60)
    print("Showing how a single unified dataset powers ALL capabilities")
    print()
    
    # Initialize unified data system
    from unified_data_system import UnifiedDataSystem
    uds = UnifiedDataSystem()
    
    print("üìä UNIFIED DATASET OVERVIEW")
    print("-" * 40)
    print(f"‚úÖ Single dataset contains:")
    print(f"   ‚Ä¢ {len(uds.master_data['locations'])} locations with complete data")
    print(f"   ‚Ä¢ {len(uds.master_data['vehicles'])} vehicles with capabilities")
    print(f"   ‚Ä¢ Real-time environmental conditions")
    print(f"   ‚Ä¢ Historical patterns and trends")
    print(f"   ‚Ä¢ Accessibility and risk assessments")
    print(f"   ‚Ä¢ Service time predictions")
    print(f"   ‚Ä¢ Vehicle capability matching")
    print()
    
    # Show how one dataset provides routing data
    print("üöõ ROUTING INTELLIGENCE FROM ONE DATASET")
    print("-" * 50)
    routing_data = uds.get_routing_data()
    print(f"üìç Depot: {routing_data['depot']['name']}")
    print(f"üìç Stops: {len(routing_data['stops'])} locations")
    print(f"üöõ Vehicles: {len(routing_data['vehicles'])} available")
    print(f"üì¶ Total Demand: {sum(s['demand'] for s in routing_data['stops'])} units")
    print(f"üì¶ Total Capacity: {sum(v['capacity'] for v in routing_data['vehicles'])} units")
    print()
    
    # Show service time predictions from one dataset
    print("‚è±Ô∏è SERVICE TIME PREDICTIONS FROM ONE DATASET")
    print("-" * 50)
    try:
        from backend.services.service_time_model import predictor_singleton
        service_data = uds.get_service_time_data()
        predictions = predictor_singleton.predict_minutes(service_data)
        
        for i, (service, pred) in enumerate(zip(service_data, predictions)):
            loc_name = next(loc['name'] for loc in uds.master_data['locations'] if loc['id'] == service['id'])
            print(f"   {loc_name}: {pred:.1f} min (demand: {service['demand']}, access: {service['access_score']:.2f})")
        print(f"‚úÖ All service times predicted from unified data")
    except Exception as e:
        print(f"‚ùå Service time prediction: {e}")
    print()
    
    # Show risk assessment from one dataset
    print("‚ö†Ô∏è RISK ASSESSMENT FROM ONE DATASET")
    print("-" * 50)
    try:
        from backend.services.risk_shaper import risk_shaper_singleton
        
        locations = uds.master_data["locations"]
        stops_order = [loc["id"] for loc in locations]
        osrm_matrix = [[0 if i == j else 10 for j in range(len(locations))] for i in range(len(locations))]
        
        features = {loc["id"]: {
            "risk": loc["crime_risk"],
            "light": loc["lighting_score"],
            "cong": loc["congestion_score"]
        } for loc in locations}
        
        multipliers = risk_shaper_singleton.shape(stops_order, osrm_matrix, 14, 2, features)
        
        print(f"   Risk matrix: {multipliers.shape[0]}x{multipliers.shape[1]}")
        print(f"   Max risk multiplier: {multipliers.max():.3f}")
        print(f"   Average risk: {multipliers.mean():.3f}")
        print(f"‚úÖ Risk assessment computed from unified data")
    except Exception as e:
        print(f"‚ùå Risk assessment: {e}")
    print()
    
    # Show accessibility analysis from one dataset
    print("‚ôø ACCESSIBILITY ANALYSIS FROM ONE DATASET")
    print("-" * 50)
    access_data = uds.get_accessibility_data()
    
    total_features = sum(len(loc["features"]) for loc in access_data)
    avg_access = sum(loc["access_score"] for loc in access_data) / len(access_data)
    hazard_locations = len([loc for loc in access_data if loc["hazards"]])
    
    print(f"   Total accessibility features: {total_features}")
    print(f"   Average access score: {avg_access:.2f}/1.0")
    print(f"   Locations with hazards: {hazard_locations}")
    print(f"   Features detected: {', '.join(set(f for loc in access_data for f in loc['features']))}")
    print(f"‚úÖ Accessibility analysis from unified data")
    print()
    
    # Show environmental intelligence from one dataset
    print("üå§Ô∏è ENVIRONMENTAL INTELLIGENCE FROM ONE DATASET")
    print("-" * 50)
    env_data = uds.get_environmental_data()
    
    weather = env_data["weather"]
    traffic = env_data["traffic"]
    
    print(f"   Weather: {weather['condition']} ({weather['temperature']}¬∞C)")
    print(f"   Humidity: {weather['humidity']}%")
    print(f"   Wind: {weather['wind_speed']} km/h")
    print(f"   Traffic: {traffic['overall_congestion']*100:.0f}% congestion")
    print(f"   Incidents: {traffic['incidents']}")
    print(f"   Construction zones: {traffic['construction_zones']}")
    print(f"‚úÖ Environmental intelligence from unified data")
    print()
    
    # Show vehicle capabilities from one dataset
    print("üöõ VEHICLE CAPABILITIES FROM ONE DATASET")
    print("-" * 50)
    vehicle_data = uds.get_vehicle_capabilities()
    
    for veh in vehicle_data["vehicles"]:
        capabilities = ', '.join(veh['capabilities']) if veh['capabilities'] else 'standard'
        print(f"   {veh['id']}: {veh['capacity']} units, {veh['type']}, {capabilities}")
    
    print(f"‚úÖ Vehicle capabilities from unified data")
    print()
    
    # Show optimization parameters from one dataset
    print("üéØ OPTIMIZATION PARAMETERS FROM ONE DATASET")
    print("-" * 50)
    opt_params = uds.get_optimization_parameters()
    
    print(f"   Time windows: {len(opt_params['time_windows'])} locations")
    print(f"   Priorities: {len(opt_params['priorities'])} locations")
    print(f"   Demands: {sum(opt_params['demands'].values())} total units")
    print(f"   Capacities: {sum(opt_params['capacities'].values())} total capacity")
    print(f"‚úÖ Optimization parameters from unified data")
    print()
    
    # Demonstrate complete routing with unified data
    print("üöõ COMPLETE ROUTING WITH UNIFIED DATA")
    print("-" * 50)
    try:
        from backend.services.ortools_solver import solve_vrp
        
        # Use unified data for routing
        routing_data = uds.get_routing_data()
        service_data = uds.get_service_time_data()
        
        # Add service times
        for stop in routing_data["stops"]:
            for service in service_data:
                if service["id"] == stop["id"]:
                    stop["service_min"] = service["historical_avg"]
                    break
        
        # Solve routing
        start_time = time.time()
        result = solve_vrp(
            depot=routing_data["depot"],
            stops=routing_data["stops"],
            vehicles=routing_data["vehicles"],
            time_limit_sec=8,
            drop_penalty_per_priority=2000,
            use_access_scores=True
        )
        solve_time = time.time() - start_time
        
        print(f"   Solve time: {solve_time:.2f}s")
        print(f"   Routes: {len(result.get('routes', []))}")
        print(f"   Distance: {result.get('summary', {}).get('total_distance_km', 'N/A')} km")
        print(f"   Served: {result.get('summary', {}).get('served_stops', 'N/A')} stops")
        print(f"‚úÖ Complete routing from unified data")
    except Exception as e:
        print(f"‚ùå Complete routing: {e}")
    print()
    
    # Final summary
    print("üéâ UNIFIED DATA SYSTEM SUMMARY")
    print("=" * 60)
    print("‚úÖ ONE DATASET PROVIDES ALL INFORMATION:")
    print("   ‚Ä¢ Complete routing intelligence")
    print("   ‚Ä¢ Service time predictions")
    print("   ‚Ä¢ Risk assessment and safety")
    print("   ‚Ä¢ Accessibility analysis")
    print("   ‚Ä¢ Environmental conditions")
    print("   ‚Ä¢ Vehicle capabilities")
    print("   ‚Ä¢ Optimization parameters")
    print("   ‚Ä¢ Historical patterns")
    print("   ‚Ä¢ Real-time updates")
    print()
    print("üöÄ BENEFITS OF UNIFIED DATA:")
    print("   ‚Ä¢ Single source of truth")
    print("   ‚Ä¢ Consistent information across all systems")
    print("   ‚Ä¢ Easy to maintain and update")
    print("   ‚Ä¢ Complete integration")
    print("   ‚Ä¢ Real-time synchronization")
    print("   ‚Ä¢ Comprehensive analysis")
    print()
    print("üéØ RESULT: ONE DATASET POWERS EVERYTHING!")

def main():
    """Main demonstration"""
    print("üéØ DEMONSTRATION: ONE DATASET, ALL INFORMATION")
    print("=" * 70)
    print("Showing how a single unified dataset provides all routing intelligence")
    print()
    
    # Change to swarmaura directory
    os.chdir("/Users/krishnabhatnagar/hackharvard/swarmaura")
    
    # Run demonstration
    demo_unified_data_power()
    
    print(f"\nüöÄ Demonstration complete!")
    print(f"‚úÖ One dataset provides all information for all capabilities!")

if __name__ == "__main__":
    main()
